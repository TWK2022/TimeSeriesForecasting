# onnx转trt，需要安装tensorrt库
# 需要压缩包中的bin、include、lib文件，然后添加lib文件路径到系统路径中
# windows为:系统->高级系统设置->环境变量->系统变量->Path中加入
# linux为:sudo ldconfig lib位置
# 然后找到对应版本的whl文件使用pip install ....whl。bin中是官方提供的onnx转trt程序
# -------------------------------------------------------------------------------------------------------------------- #
这里的导出程序实际上是tensorrt安装包中的bin里的文件。windows为trtexec.exe。linux为trtexec
windows:
export_trt.exe --onnx=best.onnx --saveEngine=best.trt --fp16 --useCudaGraph
linux:
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:lib位置
export_trt --onnx=best.onnx --saveEngine=best.trt --fp16 --useCudaGraph
# -------------------------------------------------------------------------------------------------------------------- #
# export_trt.exe：查看提示信息
# --onnx=onnx模型位置
# --saveEngine=trt模型保存位置
# --noTF32：禁用float32精度
# --fp16：启用float16精度
# --int8：启用int8精度
# --best：开启所有精度(有的模型是混合精度的)
# --device=0：使用的GPU号码，默认为0
# --useCudaGraph：尝试使用cuda图
# 转换过程中有很多提示信息，可以解决大多数问题。转换后会进行速度测试。不指定输入形状时默认为单批量预测(推荐)